# 非獨占記憶體分層（Non-Exclusive Memory Tiering）策略
類似 L1 Cache 和 L2 Cache ，且不同的記憶體可共享資料。
例如：
重要的資料同時存在於 L1 和 L2，補較不重要的資料只存於 L2 ，因為不常用到，所以偶爾在去 L2 找就好。
資源共享：
 * a.非獨占策略允許應用程式對所有層次的記憶體進行訪問，而不需要人工管理。
 * b.系統軟體（如操作系統或記憶體管理工具）負責抽象底層硬體，向應用提供統一的記憶體視圖。


# 基於頁面訪問模式動態地遷移數據
就是 page replacement 演算法，最常用的是 LRU


# 基於頁面遷移的獨占記憶體分層（Exclusive Memory Tiering）策略
主要目標是確保每個數據頁面只存在於一個記憶體層中，並基於頁面訪問模式動態地遷移數據，以達到最佳性能和資源利用率。但就要判斷 page fault 的問題


# 交易式頁面遷移（Transactional Page Migration）
目的是在不同記憶體層（如 DRAM 和 NVM）之間進行頁面遷移時，確保數據的一致性、正確性和高效性，並減少遷移過程中對系統性能的影響。
使用日志記錄遷移過程中的關鍵操作（如頁面複製、更新和釋放）。如果遷移過程因系統錯誤或中斷而失敗，可以根據日志恢復到一致的狀態。
遷移過程通常分為多個階段，以減少對系統性能的影響：
複製階段：將頁面從源層複製到目標層。
切換階段：將數據存取切換到目標層。
清理階段：釋放源層的頁面資源。


# 頁面影子機制（Page Shadowing）
是一種用於多層次記憶體管理系統的技術，其目的是在不同記憶體層之間進行數據遷移時，確保數據的一致性和訪問正確性，同時減少數據遷移對系統性能的影響。
透過為遷移中的頁面創建「影子頁面」（Shadow Page），使原始頁面可以繼續被訪問，而不影響遷移過程，並在遷移完成後切換到目標頁面，實現無縫數據訪問。
原理：
 * a.影子機制會在遷移過程中更新頁表，使得所有對原始頁面的訪問都被重定向到影子頁面。
 * b.當遷移完成並保證數據一致性後，頁表將指向目標頁面，並釋放影子頁面。
 * c.在頁面遷移期間，對影子頁面的寫操作會同時更新源頁面和目標頁面，確保數據的一致性。
 * d.一旦遷移完成，影子頁面會被移除，應用程序的訪問被完全重定向到目標頁面。
 
工作流程：
 * a.遷移觸發
系統決定某個頁面需要遷移（例如，數據從 DRAM 遷移到 NVM）。
 * b.創建影子頁面
在頁表中為遷移中的頁面創建影子頁面，影子頁面作為訪問代理，屏蔽底層遷移過程。
 * c.數據遷移
系統將源頁面的數據複製到目標頁面。
遷移期間，對影子頁面的寫操作會同步更新到源頁面和目標頁面，確保數據一致性。
 * d.頁表更新
當遷移完成後，頁表指向目標頁面，並釋放影子頁面。
 * e.釋放資源
清理源頁面和影子頁面的相關資源，完成遷移。


# Byte-Addressable Memory Devices
可以按字節粒度進行隨機讀取和寫入操作的記憶體技術，與傳統的塊位址存儲設備（如硬碟或 SSD）不同。這些記憶體技術具有類似於 DRAM 的快速隨機存取特性，同時還具備高密度、非易失性或更低功耗等特性。


# 內存下線（offlining）
指的是將一部分內存標記為不可用，從操作系統或應用程式的內存分配範圍中移除。被「下線」的內存雖然物理上仍然存在，但邏輯上對系統來說是不可訪問的。


# 透明大頁面（Transparent Huge Pages, THP）、多執行緒頁面遷移（Parallelized Data Copy）、同時遷移多個頁面（Concurrent Multi-page Migration），以及對稱頁面交換（symmetric exchange of pages）

THP：
THP 的遷移機制則是指操作系統如何在不干擾應用程式運行的情況下，將這些大頁面（Huge Pages）從一個物理位置遷移到另一個物理位置的過程。

Parallelized Data Copy：
利用 kernel workqueues，以生成輔助執行緒來在任意物理範圍之間進行數據複製。通過將頁面大小（或在 3.1.3 節中，同時遷移的頁面總量）除以工作執行緒的數量，計算每個平行執行緒需要複製的數據量。  
透過 sysfs 介面提供參數配置，使系統管理員可以啟用或禁用多執行緒的 CPU 複製，或更改參與數據複製的 CPU 數量。此外，我們在 move_pages() 系統呼叫中新增了一個可選的參數標誌 MPOL_MF_MT，以使遷移策略引擎能夠根據每次遷移的需求動態選擇平行化的層級。

Concurrent Multi-page Migration：  
Linux 的 move_pages() 介面已經支持通過單次系統呼叫來遷移多個頁面，方法是傳遞一個指向需在記憶體節點之間遷移的頁面列表的指標。然而，如圖 5a 所示，目前的實作將數據複製串列化，按頁面逐一執行。  
我們的新頁面遷移實作通過將 move_pages() 提供的頁面列表中的所有數據複製過程聚合到一個更大的邏輯步驟中，實現了多頁面同時遷移。  
列表中的每個頁面都會分配一個大小相匹配的新頁面，然後取消映射（unmapped）。接著，列表中的所有頁面根據 sysfs 配置分配到每個 CPU 的工作隊列中。  

symmetric exchange of pages：
消除了單向頁面遷移中許多不必要的內核操作，並重用了現有的物理頁面，而非分配新頁面。新增了一個 exchange_pages() 系統呼叫，該呼叫接受兩個大小相等的頁面列表。如果頁面列表不滿足要求，則呼叫者必須回退到傳統的雙步遷移過程。  
(1)取消 map  
(2)兩個 page 直接交換  
(3)map the old page  


# CXL
計算快速鏈接（Compute Express Link, CXL）【7】為此問題提供了解決方案，提供了一個與 DRAM 相似的中間延遲操作點，具有 DRAM 類似的頻寬與快取線粒度訪問語義。CXL 協議允許將新型記憶體總線介面附加到 CPU，從軟體的角度來看，CXL 記憶體呈現為一個無 CPU 的 NUMA 節點，其記憶體特性（如頻寬、容量、世代、技術等）獨立於直接附加到 CPU 的記憶體。這提供了記憶體子系統設計的靈活性以及對記憶體頻寬和容量的細粒度控制【9, 10, 24】。  
是 PCIE 介面。  
我們提出了一種稱為 TPP（透明頁面放置機制）的新型 OS 級記憶體管理方法，用於 CXL 支援的分層記憶體系統。TPP 利用輕量級機制來識別並將熱/冷頁面放置到適當的記憶體層。TPP 能夠主動將較冷的頁面從本地記憶體降級到 CXL 記憶體，為與請求處理相關且通常壽命短且熱的新頁面分配創造空間。同時，TPP 可以及時將性能關鍵的熱頁面從緩慢的 CXL 記憶體提升到快速的本地記憶體，並將取樣開銷和不必要的遷移降至最低。  
 

# TPP (Transparent Page Placement)
Transparent Page Placement 是一種記憶體管理技術，用於多層次記憶體系統（如 NUMA 系統）中，自動將頁面放置在適合的記憶體節點上，從而最大化記憶體訪問的性能。該技術對應用程式是透明的，應用程序無需手動指定數據的存放位置，操作系統會根據數據訪問模式和硬體結構，自動完成頁面的分配與遷移。  
核心是將應用程式的記憶體頁分為冷頁和熱頁, 將冷頁沉降到延遲更高的CXL記憶體,將熱頁提升到延遲更低的本地內存, 從而在幾乎不影響應用程序內存讀取速度的前提下, 大幅提升可用內存總量.  
**參考：** https://www.ctyun.cn/developer/article/465921138012229 、 https://lrl52.top/1105/pond-and-tpp/


# Memtis 和 TMTS 利用硬體性能計數器來減輕頁面訪問追蹤的開銷，並使用後台執行緒定期非同步地提升頁面。  
***1. 硬體性能計數器（Hardware Performance Counters）***
 * 硬體性能計數器 是現代處理器中的一組專用寄存器，用於監控和統計系統性能數據。例如：
   * 每個內存頁面的訪問次數。
   * 緩存命中或缺失的情況。
   * CPU 指令執行數量或內存讀寫次數。
 * Memtis 和 TMTS 使用這些計數器來追蹤內存頁面的訪問行為，而不需要額外插入軟體監控代碼，從而減少了軟體實現的額外計算和性能開銷。

***2. 頁面訪問追蹤的開銷***
 * 傳統方法的挑戰：
   * 在多層次記憶體系統（如 DRAM 和 NVM）中，操作系統需要頻繁追蹤每個頁面的訪問次數，以決定哪些頁面應該留在高速記憶體（如 DRAM），哪些頁面可以移到慢速記憶體（如 NVM）。
   * 傳統方法可能通過軟體層進行監控，例如插入計數代碼或周期性掃描，這會增加系統負擔，降低性能。
 * Memtis 和 TMTS 的改進：
   * 利用硬體性能計數器，直接從硬體層級獲取頁面的訪問數據，避免軟體插入代碼造成的性能損耗，從而大幅減輕頁面訪問追蹤的開銷。

***3. 非同步後台執行緒（Background Threads）***
 * 非同步處理 是指在應用程序正常執行的同時，將頁面提升（promotion，即從慢速記憶體遷移到快速記憶體）或其他內存管理操作交由後台執行緒處理。
 * Memtis 和 TMTS 的運作方式：
   * 後台執行緒根據硬體性能計數器收集的數據，定期分析哪些頁面是「熱頁面」（頻繁訪問的頁面）。
   * 將這些熱頁面從慢速記憶體（如 NVM）提升到快速記憶體（如 DRAM）。
   * 非同步執行的好處是：
     * 不會阻塞主應用程序的執行。
     * 能夠在系統空閒時處理頁面提升操作，最大限度地降低對應用程序性能的影響。

***4. 頁面提升（Page Promotion）***
 * 頁面提升 是指將訪問頻繁的頁面從較慢的記憶體（例如 NVM）遷移到較快的記憶體（例如 DRAM），以減少內存訪問的延遲。
 * Memtis 和 TMTS 的策略：
   * 後台執行緒根據硬體性能計數器的數據分析熱頁面。
   * 自動將這些頁面提升到快速記憶體，從而優化應用程序的內存訪問性能。

### Memtis 是什麼？
Memtis 是一種專門針對多層次記憶體架構的頁面管理系統，目的是：
1. 動態管理熱頁面與冷頁面：根據頁面的訪問熱度，動態將頻繁訪問的頁面（熱頁面）放置於快速記憶體（如 DRAM），而將不常訪問的頁面（冷頁面）移至慢速記憶體（如 NVM）。
2. 利用硬體性能計數器：Memtis 使用硬體性能計數器（如 CPU 的訪問跟蹤功能）來追蹤頁面的訪問模式，而不依賴額外的軟體監控代碼。
3. 非同步處理：頁面提升和遷移操作由後台執行緒完成，減少對主應用程式的影響。

核心特性
 * 硬體輔助頁面追蹤：利用硬體性能計數器來監控每個頁面的訪問頻率，降低頁面追蹤開銷。
 * 多層次記憶體支持：自動在 DRAM 和 NVM 之間移動頁面，實現性能和資源利用的平衡。
 * 透明性：對應用程式完全透明，不需要應用程式參與內存管理。

適用場景
 * 數據密集型應用，如資料庫系統、大規模數據處理任務。
 * 高效能運算（HPC）場景，需動態優化內存資源分配。

### TMTS 是什麼？
TMTS 是另一種多層次記憶體管理系統，專注於：
1. 頁面追蹤的低開銷：與 Memtis 相似，TMTS 利用硬體性能計數器追蹤頁面訪問模式，減少軟體層監控的額外負擔。
2. 非同步提升（Promotion）：通過後台執行緒定期分析訪問模式，並將熱頁面從慢速記憶體提升到快速記憶體。

核心特性
 * 後台優化機制：TMTS 的頁面提升和遷移完全由後台執行緒完成，不會干擾應用程序的正常運行。
 * 提升效率：自動將熱數據遷移至 DRAM，優化訪問延遲，提升內存訪問性能。
 * 架構靈活性：適應不同的記憶體層級結構，特別是 DRAM 和非易失性記憶體（如 3D XPoint 或 NAND Flash）的混合架構。

適用場景
 * 虛擬化環境和多租戶雲端服務，需在不同記憶體層中靈活調配資源。
 * 人工智慧（AI）和機器學習（ML）應用中，需處理大規模熱數據的場景。

### Memtis 與 TMTS 的共通點
1. 硬體性能計數器
 * 兩者都利用硬體性能計數器來減少頁面追蹤的軟體開銷。
 * 硬體層監控頁面的訪問頻率和模式，為頁面放置策略提供數據支持。
2. 非同步操作
 * 兩者都採用後台執行緒，非同步地執行頁面提升（promotion）或遷移，降低主線程的負擔。
3. 頁面提升與遷移
 * 兩者都支持動態將熱頁面提升至高速記憶體，冷頁面降級至慢速記憶體，實現多層次記憶體的最佳利用。
4. 透明性
 * 兩者對應用程式完全透明，不需要開發者手動指定頁面位置。

### Memtis 與 TMTS 的差異
| **特性**       | **Memtis**                     | **TMTS**                       |
|---------------|-------------------------------|---------------------------------|
| **頁面追蹤**   | 硬體性能計算器，專注於多層次記憶體管理  | 同樣利用硬體性能計算器，並優化追蹤效率 |
| **處理方式**   | 注重全局內存管理，動態提升和遷移頁面    | 側重於非同步優化，提升熱頁面到高速記憶體 |
| **適用場景**   | 數據密集型應用、大數據處理            | 雲服務、虛擬化環境、AI/ML 訓練場景     |












































